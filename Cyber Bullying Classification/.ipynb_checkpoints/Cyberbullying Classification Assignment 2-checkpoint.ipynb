{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://www.kaggle.com/datasets/andrewmvd/cyberbullying-classification\n",
    "\n",
    "Download dataset from above link, you will predict if given sentence is bullying\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Assignment (End-to-End)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns, warnings\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import string # from some string manipulation tasks\n",
    "import nltk # natural language toolkit\n",
    "import re # regex\n",
    "from string import punctuation # solving punctuation problems\n",
    "from nltk.corpus import stopwords # stop words in sentences\n",
    "from nltk.stem import WordNetLemmatizer # For stemming the sentence\n",
    "from nltk.stem import SnowballStemmer # For stemming the sentence\n",
    "from contractions import contractions_dict # to solve contractions\n",
    "from autocorrect import Speller #correcting the spellings\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "#Data preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#Naive Bayes\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@Raja5aab @Quickieleaks Yes, the test of god i...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Itu sekolah ya bukan tempat bully! Ga jauh kay...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Karma. I hope it bites Kat on the butt. She is...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@stockputout everything but mostly my priest</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rebecca Black Drops Out of School Due to Bully...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text cyberbullying_type\n",
       "0  In other words #katandandre, your food was cra...  not_cyberbullying\n",
       "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
       "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
       "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
       "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying\n",
       "5  @Raja5aab @Quickieleaks Yes, the test of god i...  not_cyberbullying\n",
       "6  Itu sekolah ya bukan tempat bully! Ga jauh kay...  not_cyberbullying\n",
       "7  Karma. I hope it bites Kat on the butt. She is...  not_cyberbullying\n",
       "8       @stockputout everything but mostly my priest  not_cyberbullying\n",
       "9  Rebecca Black Drops Out of School Due to Bully...  not_cyberbullying"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data understanding\n",
    "df = pd.read_csv(r\"A:\\datasets\\cyberbullying_tweets.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47692 entries, 0 to 47691\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   tweet_text          47692 non-null  object\n",
      " 1   cyberbullying_type  47692 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 745.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "religion               7998\n",
       "age                    7992\n",
       "gender                 7973\n",
       "ethnicity              7961\n",
       "not_cyberbullying      7945\n",
       "other_cyberbullying    7823\n",
       "Name: cyberbullying_type, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cyberbullying_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Due to the imbalance in the data 'other_cyberbullying' is dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "religion             7998\n",
       "age                  7992\n",
       "gender               7973\n",
       "ethnicity            7961\n",
       "not_cyberbullying    7945\n",
       "Name: cyberbullying_type, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df[df['cyberbullying_type'] == 'other_cyberbullying'].index, inplace = True)\n",
    "df['cyberbullying_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47687</th>\n",
       "      <td>Black ppl aren't expected to do anything, depe...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>Turner did not withhold his disappointment. Tu...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>I swear to God. This dumb nigger bitch. I have...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>Yea fuck you RT @therealexel: IF YOURE A NIGGE...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39869 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text cyberbullying_type\n",
       "0      In other words #katandandre, your food was cra...  not_cyberbullying\n",
       "1      Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
       "2      @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
       "3      @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
       "4      @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying\n",
       "...                                                  ...                ...\n",
       "47687  Black ppl aren't expected to do anything, depe...          ethnicity\n",
       "47688  Turner did not withhold his disappointment. Tu...          ethnicity\n",
       "47689  I swear to God. This dumb nigger bitch. I have...          ethnicity\n",
       "47690  Yea fuck you RT @therealexel: IF YOURE A NIGGE...          ethnicity\n",
       "47691  Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...          ethnicity\n",
       "\n",
       "[39869 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cyberbullying_type\"].replace({\"religion\": 1, \"age\": 2, \"gender\": 3, \"ethnicity\": 4, \"not_cyberbullying\": 5}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = [\"religion\",\"age\",\"gender\",\"ethnicity\",\"not bullying\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text cleaning\n",
    "import re, string\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#Clean emojis from text\n",
    "def strip_emoji(text):\n",
    "\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return(emoji_pattern.sub(r'', text)) # no emoji\n",
    "    \n",
    "\n",
    "#Remove punctuations, links, stopwords, mentions and \\r\\n new line characters\n",
    "def strip_all_entities(text): \n",
    "    text = text.replace('\\r', '').replace('\\n', ' ').lower() #remove \\n and \\r and lowercase\n",
    "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text) #remove links and mentions\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r'', text) #remove non utf8/ascii characters such as '\\x9a\\x91\\x97\\x9a\\x97'\n",
    "    banned_list= string.punctuation\n",
    "    table = str.maketrans('', '', banned_list)\n",
    "    text = text.translate(table)\n",
    "    text = [word for word in text.split() if word not in stop_words]\n",
    "    text = ' '.join(text)\n",
    "    text =' '.join(word for word in text.split() if len(word) < 14) # remove words longer than 14 characters\n",
    "    return text\n",
    "\n",
    "#remove contractions\n",
    "def decontract(text):\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    return text\n",
    "\n",
    "#clean hashtags at the end of the sentence, and keep those in the middle of the sentence by removing just the \"#\" symbol\n",
    "def clean_hashtags(tweet):\n",
    "    new_tweet = \" \".join(word.strip() for word in re.split('#(?!(?:hashtag)\\b)[\\w-]+(?=(?:\\s+#[\\w-]+)*\\s*$)', tweet)) #remove last hashtags\n",
    "    new_tweet2 = \" \".join(word.strip() for word in re.split('#|_', new_tweet)) #remove hashtags symbol from words in the middle of the sentence\n",
    "    return new_tweet2\n",
    "\n",
    "#Filter special characters such as \"&\" and \"$\" present in some words\n",
    "def filter_chars(a):\n",
    "    sent = []\n",
    "    for word in a.split(' '):\n",
    "        if ('$' in word) | ('&' in word):\n",
    "            sent.append('')\n",
    "        else:\n",
    "            sent.append(word)\n",
    "    return ' '.join(sent)\n",
    "\n",
    "#Remove multiple sequential spaces\n",
    "def remove_mult_spaces(text):\n",
    "    return re.sub(\"\\s\\s+\" , \" \", text)\n",
    "\n",
    "#Stemming\n",
    "def stemmer(text):\n",
    "    tokenized = nltk.word_tokenize(text)\n",
    "    ps = PorterStemmer()\n",
    "    return ' '.join([ps.stem(words) for words in tokenized])\n",
    "\n",
    "#Lemmatization \n",
    "def lemmatize(text):\n",
    "    tokenized = nltk.word_tokenize(text)\n",
    "    lm = WordNetLemmatizer()\n",
    "    return ' '.join([lm.lemmatize(words) for words in tokenized])\n",
    "\n",
    "#Then we apply all the defined functions in the following order\n",
    "def preprocess(text):\n",
    "    text = strip_emoji(text)\n",
    "    text = decontract(text)\n",
    "    text = strip_all_entities(text)\n",
    "    text = clean_hashtags(text)\n",
    "    text = filter_chars(text)\n",
    "    text = remove_mult_spaces(text)\n",
    "    text = stemmer(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_cleaned = []\n",
    "for t in df.tweet_text:\n",
    "    texts_cleaned.append(preprocess(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = texts_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>5</td>\n",
       "      <td>word katandandr food crapilici mkr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>5</td>\n",
       "      <td>aussietv white mkr theblock today sunris studi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>5</td>\n",
       "      <td>classi whore red velvet cupcak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>5</td>\n",
       "      <td>meh p thank head concern anoth angri dude twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>5</td>\n",
       "      <td>isi account pretend kurdish account like islam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  cyberbullying_type  \\\n",
       "0  In other words #katandandre, your food was cra...                   5   \n",
       "1  Why is #aussietv so white? #MKR #theblock #ImA...                   5   \n",
       "2  @XochitlSuckkks a classy whore? Or more red ve...                   5   \n",
       "3  @Jason_Gio meh. :P  thanks for the heads up, b...                   5   \n",
       "4  @RudhoeEnglish This is an ISIS account pretend...                   5   \n",
       "\n",
       "                                          text_clean  \n",
       "0                 word katandandr food crapilici mkr  \n",
       "1  aussietv white mkr theblock today sunris studi...  \n",
       "2                     classi whore red velvet cupcak  \n",
       "3  meh p thank head concern anoth angri dude twitter  \n",
       "4  isi account pretend kurdish account like islam...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1049"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text_clean\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(\"text_clean\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7946\n",
       "2    7884\n",
       "4    7746\n",
       "5    7637\n",
       "3    7607\n",
       "Name: cyberbullying_type, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cyberbullying_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_len = []\n",
    "for text in df.text_clean:\n",
    "    tweet_len = len(text.split())\n",
    "    text_len.append(tweet_len)\n",
    "df['text_len'] = text_len\n",
    "plt.figure(figsize=(7,5))\n",
    "ax = sns.countplot(x='text_len', data=df[df['text_len']<10], palette='mako')\n",
    "plt.title('Count of tweets with less than 10 words', fontsize=20)\n",
    "plt.yticks([])\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44035</th>\n",
       "      <td>You so black and white trying to live like a n...</td>\n",
       "      <td>4</td>\n",
       "      <td>black white tri live like nigger pahahahaha co...</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45165</th>\n",
       "      <td>@hermdiggz: “@tayyoung_: FUCK OBAMA, dumb ass ...</td>\n",
       "      <td>4</td>\n",
       "      <td>fuck obama dumb ass nigger bitch ltthi whore s...</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33724</th>\n",
       "      <td>... I don't feel guilty for killing him, I jus...</td>\n",
       "      <td>2</td>\n",
       "      <td>feel guilti kill feel guilti enjoy torment sin...</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>@EurekAlertAAAS: Researchers push to import to...</td>\n",
       "      <td>5</td>\n",
       "      <td>research push import top antibulli program us ...</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47037</th>\n",
       "      <td>@Purely_Ambition: Sooo mad. RT @TracePeterson ...</td>\n",
       "      <td>4</td>\n",
       "      <td>sooo mad rt fuck obama dumb nigger go switzerl...</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>@harmlesstree2 Here7 https://t.co/xWJzpSodGj</td>\n",
       "      <td>5</td>\n",
       "      <td>here7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6696</th>\n",
       "      <td>@LiamTighe Rebecca who?</td>\n",
       "      <td>5</td>\n",
       "      <td>rebecca</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>@root_tim this is my work :)</td>\n",
       "      <td>5</td>\n",
       "      <td>work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>@jaredchase killing you how?</td>\n",
       "      <td>5</td>\n",
       "      <td>kill</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@Jord_Is_Dead http://t.co/UsQInYW5Gn</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38820 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text  cyberbullying_type  \\\n",
       "44035  You so black and white trying to live like a n...                   4   \n",
       "45165  @hermdiggz: “@tayyoung_: FUCK OBAMA, dumb ass ...                   4   \n",
       "33724  ... I don't feel guilty for killing him, I jus...                   2   \n",
       "1317   @EurekAlertAAAS: Researchers push to import to...                   5   \n",
       "47037  @Purely_Ambition: Sooo mad. RT @TracePeterson ...                   4   \n",
       "...                                                  ...                 ...   \n",
       "1607        @harmlesstree2 Here7 https://t.co/xWJzpSodGj                   5   \n",
       "6696                             @LiamTighe Rebecca who?                   5   \n",
       "558                         @root_tim this is my work :)                   5   \n",
       "3462                        @jaredchase killing you how?                   5   \n",
       "10                  @Jord_Is_Dead http://t.co/UsQInYW5Gn                   5   \n",
       "\n",
       "                                              text_clean  text_len  \n",
       "44035  black white tri live like nigger pahahahaha co...       187  \n",
       "45165  fuck obama dumb ass nigger bitch ltthi whore s...       162  \n",
       "33724  feel guilti kill feel guilti enjoy torment sin...       137  \n",
       "1317   research push import top antibulli program us ...       137  \n",
       "47037  sooo mad rt fuck obama dumb nigger go switzerl...       125  \n",
       "...                                                  ...       ...  \n",
       "1607                                               here7         1  \n",
       "6696                                             rebecca         1  \n",
       "558                                                 work         1  \n",
       "3462                                                kill         1  \n",
       "10                                                               0  \n",
       "\n",
       "[38820 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['text_len'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>5</td>\n",
       "      <td>word katandandr food crapilici mkr</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>5</td>\n",
       "      <td>aussietv white mkr theblock today sunris studi...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>5</td>\n",
       "      <td>classi whore red velvet cupcak</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>5</td>\n",
       "      <td>meh p thank head concern anoth angri dude twitter</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>5</td>\n",
       "      <td>isi account pretend kurdish account like islam...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47687</th>\n",
       "      <td>Black ppl aren't expected to do anything, depe...</td>\n",
       "      <td>4</td>\n",
       "      <td>black ppl expect anyth depend anyth yet free p...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>Turner did not withhold his disappointment. Tu...</td>\n",
       "      <td>4</td>\n",
       "      <td>turner withhold turner call court abomin concl...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>I swear to God. This dumb nigger bitch. I have...</td>\n",
       "      <td>4</td>\n",
       "      <td>swear god dumb nigger bitch got bleach hair re...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>Yea fuck you RT @therealexel: IF YOURE A NIGGE...</td>\n",
       "      <td>4</td>\n",
       "      <td>yea fuck rt your nigger fuck unfollow fuck dum...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...</td>\n",
       "      <td>4</td>\n",
       "      <td>bro u got ta chill rt dog fuck kp dumb nigger ...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37114 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text  cyberbullying_type  \\\n",
       "0      In other words #katandandre, your food was cra...                   5   \n",
       "1      Why is #aussietv so white? #MKR #theblock #ImA...                   5   \n",
       "2      @XochitlSuckkks a classy whore? Or more red ve...                   5   \n",
       "3      @Jason_Gio meh. :P  thanks for the heads up, b...                   5   \n",
       "4      @RudhoeEnglish This is an ISIS account pretend...                   5   \n",
       "...                                                  ...                 ...   \n",
       "47687  Black ppl aren't expected to do anything, depe...                   4   \n",
       "47688  Turner did not withhold his disappointment. Tu...                   4   \n",
       "47689  I swear to God. This dumb nigger bitch. I have...                   4   \n",
       "47690  Yea fuck you RT @therealexel: IF YOURE A NIGGE...                   4   \n",
       "47691  Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...                   4   \n",
       "\n",
       "                                              text_clean  text_len  \n",
       "0                     word katandandr food crapilici mkr         5  \n",
       "1      aussietv white mkr theblock today sunris studi...        10  \n",
       "2                         classi whore red velvet cupcak         5  \n",
       "3      meh p thank head concern anoth angri dude twitter         9  \n",
       "4      isi account pretend kurdish account like islam...         8  \n",
       "...                                                  ...       ...  \n",
       "47687  black ppl expect anyth depend anyth yet free p...        21  \n",
       "47688  turner withhold turner call court abomin concl...        28  \n",
       "47689  swear god dumb nigger bitch got bleach hair re...        13  \n",
       "47690  yea fuck rt your nigger fuck unfollow fuck dum...        10  \n",
       "47691  bro u got ta chill rt dog fuck kp dumb nigger ...        13  \n",
       "\n",
       "[37114 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['text_len'] > 3]\n",
    "df = df[df['text_len'] < 100]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<37114x32979 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 504608 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Turning text into numbers\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "clf = CountVectorizer()\n",
    "\n",
    "X_cv =  clf.fit_transform(df['text_clean'])\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_cv)\n",
    "X_tf = tf_transformer.transform(X_cv)\n",
    "X_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6314\n",
       "2    6264\n",
       "4    6167\n",
       "3    5849\n",
       "5    5097\n",
       "Name: cyberbullying_type, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tf, df['cyberbullying_type'], test_size=0.20, stratify=df['cyberbullying_type'], random_state=42)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW and TF-IDF representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id=['Navie Bayes Classifier', 'SVC classifier', 'Decision Tree', 'Random Forest Classifier']\n",
    "accuracy=[]\n",
    "f1=[]\n",
    "precision=[]\n",
    "recall=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navie Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1543   15   51   57  196]\n",
      " [  15 1540   40   69  360]\n",
      " [  11    4 1240   13  146]\n",
      " [   7    6   59 1402  100]\n",
      " [   3    1   72    1  472]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.83      0.90      1862\n",
      "           2       0.98      0.76      0.86      2024\n",
      "           3       0.85      0.88      0.86      1414\n",
      "           4       0.91      0.89      0.90      1574\n",
      "           5       0.37      0.86      0.52       549\n",
      "\n",
      "    accuracy                           0.83      7423\n",
      "   macro avg       0.82      0.84      0.81      7423\n",
      "weighted avg       0.90      0.83      0.85      7423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, classification_report, precision_score, recall_score\n",
    "\n",
    "gnb = MultinomialNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "prediction = gnb.predict(X_test)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(prediction,y_test))\n",
    "print()\n",
    "print('Classification Report:')\n",
    "print(classification_report(prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1373   39   40   32  114]\n",
      " [  38 1421   50   46  204]\n",
      " [  47   28 1211   42  180]\n",
      " [  57   39   67 1402  128]\n",
      " [  64   39   94   20  648]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.86      0.86      1598\n",
      "           2       0.91      0.81      0.85      1759\n",
      "           3       0.83      0.80      0.82      1508\n",
      "           4       0.91      0.83      0.87      1693\n",
      "           5       0.51      0.75      0.61       865\n",
      "\n",
      "    accuracy                           0.82      7423\n",
      "   macro avg       0.80      0.81      0.80      7423\n",
      "weighted avg       0.84      0.82      0.82      7423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "prediction = knn_clf.predict(X_test)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(prediction,y_test))\n",
    "print()\n",
    "print('Classification Report:')\n",
    "print(classification_report(prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1512    1    4    3   49]\n",
      " [   1 1539    2    2   39]\n",
      " [   9    0 1274    5   46]\n",
      " [   0    1    2 1521   10]\n",
      " [  57   25  180   11 1130]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.96      0.96      1569\n",
      "           2       0.98      0.97      0.98      1583\n",
      "           3       0.87      0.96      0.91      1334\n",
      "           4       0.99      0.99      0.99      1534\n",
      "           5       0.89      0.81      0.84      1403\n",
      "\n",
      "    accuracy                           0.94      7423\n",
      "   macro avg       0.94      0.94      0.94      7423\n",
      "weighted avg       0.94      0.94      0.94      7423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train, y_train)\n",
    "prediction = rf_clf.predict(X_test)\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(prediction,y_test))\n",
    "print()\n",
    "print('Classification Report:')\n",
    "print(classification_report(prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1407    1    2    7   38]\n",
      " [   3 1515    1    3   28]\n",
      " [   5    0 1149    5   22]\n",
      " [  11    4    4 1484    5]\n",
      " [ 153   46  306   43 1181]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.97      0.93      1455\n",
      "           2       0.97      0.98      0.97      1550\n",
      "           3       0.79      0.97      0.87      1181\n",
      "           4       0.96      0.98      0.97      1508\n",
      "           5       0.93      0.68      0.79      1729\n",
      "\n",
      "    accuracy                           0.91      7423\n",
      "   macro avg       0.91      0.92      0.91      7423\n",
      "weighted avg       0.91      0.91      0.90      7423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=20)\n",
    "tree.fit(X_train,y_train)\n",
    "prediction = tree.predict(X_test)\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(prediction,y_test))\n",
    "print()\n",
    "print('Classification Report:')\n",
    "print(classification_report(prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1491    1    5    4   43]\n",
      " [   1 1521    7    2   68]\n",
      " [   3    2 1267    7   33]\n",
      " [   6    0    5 1504   13]\n",
      " [  78   42  178   25 1117]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.97      0.95      1544\n",
      "           2       0.97      0.95      0.96      1599\n",
      "           3       0.87      0.97      0.91      1312\n",
      "           4       0.98      0.98      0.98      1528\n",
      "           5       0.88      0.78      0.82      1440\n",
      "\n",
      "    accuracy                           0.93      7423\n",
      "   macro avg       0.93      0.93      0.93      7423\n",
      "weighted avg       0.93      0.93      0.93      7423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(C=1, kernel='rbf')\n",
    "svc.fit(X_train,y_train)\n",
    "prediction = svc.predict(X_test)\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(prediction,y_test))\n",
    "print()\n",
    "print('Classification Report:')\n",
    "print(classification_report(prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1491    2    5    4   44]\n",
      " [   1 1518    5    2   70]\n",
      " [   5    4 1277    8   52]\n",
      " [   5    0    6 1503   15]\n",
      " [  77   42  169   25 1093]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.96      0.95      1546\n",
      "           2       0.97      0.95      0.96      1596\n",
      "           3       0.87      0.95      0.91      1346\n",
      "           4       0.97      0.98      0.98      1529\n",
      "           5       0.86      0.78      0.82      1406\n",
      "\n",
      "    accuracy                           0.93      7423\n",
      "   macro avg       0.92      0.92      0.92      7423\n",
      "weighted avg       0.93      0.93      0.93      7423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "prediction = lr.predict(X_test)\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(prediction,y_test))\n",
    "print()\n",
    "print('Classification Report:')\n",
    "print(classification_report(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score (Multinomial Naive Bayes Classifier): 0.8314640800242498\n",
      "Cross validation score (K Nearest Neighbor): 0.8054292546562931\n",
      "Cross validation score (Random Forest Classifier): 0.9368832306086019\n",
      "Cross validation score (Decision Tree): 0.9090970327708733\n",
      "Cross validation score (SVC): 0.9238489778047221\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "NB_cv_score = cross_val_score(nb_clf,X_train, y_train, cv=3)\n",
    "KNN_cv_score = cross_val_score(knn_clf,X_train, y_train, cv=3)\n",
    "RF_cv_score = cross_val_score(rf_clf,X_train, y_train, cv=3)\n",
    "DT_cv_score = cross_val_score(tree, X_train, y_train, cv=3)\n",
    "SVC_cv_score = cross_val_score(svc, X_train, y_train, cv=3)\n",
    "LR_cv_score = cross_val_score(lr, X_train, y_train, cv=3)\n",
    "\n",
    "print('Cross validation score (Multinomial Naive Bayes Classifier):', NB_cv_score.mean())\n",
    "print('Cross validation score (K Nearest Neighbor):', KNN_cv_score.mean())\n",
    "print('Cross validation score (Random Forest Classifier):', RF_cv_score.mean())\n",
    "print('Cross validation score (Decision Tree):',DT_cv_score.mean())\n",
    "print('Cross validation score (SVC):', SVC_cv_score.mean())\n",
    "print('Cross validation score (SVC):', LR_cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement grid search for the best model, recommend best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = { \n",
    "    'svm':{\n",
    "        'model':SVC(gamma='auto'),\n",
    "        'params':{ \n",
    "            'C':[1,10,20],\n",
    "            'kernel':['rbf','linear']\n",
    "        }\n",
    "    },    \n",
    "    'random_forest':{\n",
    "        'model':RandomForestClassifier(),\n",
    "        'params':{\n",
    "            'n_estimators':[1,5,10]\n",
    "        }\n",
    "    },    \n",
    "    'logistic_regression':{\n",
    "        'model':LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params':{\n",
    "            'C':[1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scores=[]\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'],mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train,y_train)\n",
    "    scores.append({\n",
    "        'model':model_name,\n",
    "        'best_score':clf.best_score_,\n",
    "        'best_params':clf.best_params_\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.927689</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.921087</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.926611</td>\n",
       "      <td>{'C': 5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score                   best_params\n",
       "0                  svm    0.927689  {'C': 1, 'kernel': 'linear'}\n",
       "1        random_forest    0.921087          {'n_estimators': 10}\n",
       "2  logistic_regression    0.926611                      {'C': 5}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
